session 1 
<<<Single node kubernate Clustor using minikube>> only use in developement or learning purpose not used in production
======
Install miniqube
for windows > check systeminfo >> Hyper -v Requirements should be all yes
download minikube for windows minikube-windows-amd64.exe
install kubectl
create folder in c drive with kubernates and paste downloaded minikube and kubectl
copy path c:/kubernates
advance system setting set environment varible user variable path and paste location
done
rename file in c:/kubernates minkube-windows-amd64.exe to minikube
now run command minikube
it will show the help menu

minikube start >> it will create vm in which kubernate cluster will be setup
done 
kubernates are setup in vm 
kubectl >> kubernates client which help to run commands or operations on kubernate clustor
kubectl get pods >> it will show the pods running
minikube ip >> it will show ip of our running minikube vm
minikube ssh >> it will give ssh access
minikube ssh username = docker
minikube ssh password = tcuser
how to provide dashboard to minikube >> minikube dashboard  command
=======================================================================================
session2
3-node kubernates clustor in vm
we need kubernates master, k8 worker1, k8 worker2. 3 virtual machines
all vm have at least 2 cpu 
all vm are in same network should be able to ping each other
go to vm file preferences>network>addnetwork>network name>ok
vm node setting network selct from list
check ip address of all vms and note down
ssh all 3 vm in ubuntu or kali or wsl this node must be able to ping all 3 vms
ssh username@ip enter then password
every node must have swapoff
to check free -h in all 3 nodes
to disable or off swap > swapoff -a try as root user
this is temporary to make it permananat we need to add in fstab
vim /etc/fstab
commet all lines start with swap in all nodes
we need to install docker in all 3 nodes but note that we should check which version
of docker is supported by k8s to check that follow k8s documentation
install docker in all vms version 19.
sudo cat /sys/class/dmi/id/product_uuid this should be unique in all node
iptables for ubuntu 19.04 or later  
*sudo apt-get update
sudo apt-get install -y apt-transport-https ca-certificates curl

*sudo curl -fsSLo /etc/apt/keyrings/kubernetes-archive-keyring.gpg https://packages.cloud.google.com/apt/doc/apt-key.gpg

*echo "deb [signed-by=/etc/apt/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main" | sudo tee /etc/apt/sources.list.d/kubernetes.list

*sudo apt-get update
sudo apt-get install -y kubelet kubeadm kubectl
sudo apt-mark hold kubelet kubeadm kubectl

do this in all nodes



master setup using kubeadm

kubeadm init --pod-network-cidr=10.244.0.0/16

kubectl get nodes to show the nodes in my cluster 
it will not work we need to enter commands to start our cluster
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernates/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(is -g) $HOME/.kube/config

kubectl get nodes >> it will show our nodes in clustor

get pods -A

kubectl apply funnel networking 
get pods -A

kubeadm join wali command copy and paste in worker nodes

kubectl get nodes on master to check all nodes are ready or not



âœ”ğ—£ğ—¼ğ—±: A Pod is the smallest and most basic unit in Kubernetes. It represents a single instance of a running process or a set of tightly coupled processes running together on a node. Pods are scheduled and managed by Kubernetes.

âœ”ğ—–ğ—¹ğ˜‚ğ˜€ğ˜ğ—²ğ—¿: A cluster is a collection of nodes that function as a single entity. It represents every element of the Kubernetes system, including the worker nodes and the control plane parts.

âœ”ğ—¡ğ—¼ğ—±ğ—²: A Node is a Kubernetes cluster's worker computer. Either a real or virtual machine may be used. The operating and management of the pods is done by the nodes.

âœ”ğ—–ğ—¼ğ—»ğ˜ğ—¿ğ—¼ğ—¹-ğ—£ğ—¹ğ—®ğ—»ğ—²: The Kubernetes cluster is managed and controlled by a group of components known as the control plane. It contains the controller manager, scheduler, etcd, and API server.

âœ” ğ—²ğ˜ğ—°ğ—±: Kubernetes uses the distributed key-value store etcd to store configuration and cluster data. For storing cluster state, it offers a dependable and highly accessible data store.

âœ”ğ—¦ğ—°ğ—µğ—²ğ—±ğ˜‚ğ—¹ğ—²ğ—¿: The Scheduler is in charge of allocating pods to nodes in accordance with resource needs, node availability, and other limitations. It selects the appropriate node for scheduling a pod.

âœ”ğ—–ğ—¼ğ—»ğ˜ğ—¿ğ—¼ğ—¹ğ—¹ğ—²ğ—¿-ğ— ğ—®ğ—»ğ—®ğ—´ğ—²ğ—¿: A group of controllers known as the Controller Manager which manages various cluster components. The Node Controller, Replication Controller, and Service Controller are a few examples. They make sure that the cluster's desired and actual states are same.

âœ”ğ—¦ğ—²ğ—¿ğ˜ƒğ—¶ğ—°ğ—²: A logical set of pods and a policy for accessing them are defined by a service, which is an abstraction. For the pods behind it, it offers a reliable network endpoint (IP address) and load balancing.

âœ”ğ—¥ğ—²ğ—½ğ—¹ğ—¶ğ—°ğ—®ğ—¦ğ—²ğ˜: ReplicaSets are Kubernetes objects that guarantee a certain number of pod replicas are active at all times. Scaling and managing the number of pods for a certain application are done using it.

âœ”ğ—¡ğ—®ğ—ºğ—²ğ˜€ğ—½ğ—®ğ—°ğ—²: The cluster resources can be split up into virtual clusters using namespaces. It gives names a range and enables many teams or projects to share the same physical cluster while isolating their resources.
===========================================================================================================================

Chatper=5

ğŸ”¹ Rolling Updates & Rollbacks in Kubernetes=>

Kubernetes supports Rolling Updates to update applications with zero downtime and Rollbacks to revert changes if something goes wrong.
ğŸš€ Rolling Update

A Rolling Update ensures that new versions of an application are deployed gradually, replacing old Pods one at a time to avoid downtime.
âœ… Steps of a Rolling Update:

    Kubernetes starts a new Pod with the updated version.
    It waits for the new Pod to become ready.
    Once ready, it removes an old Pod.
    This repeats until all old Pods are replaced.

ğŸ“Œ Example: Deployment with Rolling Update

apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-app
spec:
  replicas: 3
  selector:
    matchLabels:
      app: my-app
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1   # Max new pods above the desired count
      maxUnavailable: 1  # Max old pods that can be unavailable during update
  template:
    metadata:
      labels:
        app: my-app
    spec:
      containers:
      - name: my-app-container
        image: my-app:v1  # Initial version
        ports:
        - containerPort: 80

ğŸš€ How to Perform a Rolling Update?

Update the image of the Deployment:

kubectl set image deployment/my-app my-app-container=my-app:v2

This triggers a Rolling Update to replace my-app:v1 with my-app:v2 gradually.
ğŸ“Œ Check Update Status:

kubectl rollout status deployment/my-app

ğŸ”„ Rollback a Deployment

If an update introduces issues, you can rollback to the previous version.
âœ… Steps of a Rollback:

    Kubernetes stops the faulty Pods.
    It restarts the previous working version.

ğŸš€ How to Perform a Rollback?

Rollback to the last working version:

kubectl rollout undo deployment/my-app

Rollback to a specific revision:

kubectl rollout undo deployment/my-app --to-revision=2

ğŸ“Œ Check Deployment History:

kubectl rollout history deployment/my-app


ChatGPT
ğŸ”„ Jump to a Specific Revision in a Rolling Update

If a Kubernetes Rolling Update has multiple revisions and you need to roll back to a specific version, follow these steps:
âœ… Step 1: Check Deployment History

kubectl rollout history deployment myapp-deployment

This lists all the available revisions, showing metadata for each.

Example Output:

REVISION  CHANGE-CAUSE
1         First deployment
2         Updated image to v2
3         Updated image to v3

âœ… Step 2: Roll Back to a Specific Revision

Use the --to-revision flag:

kubectl rollout undo deployment myapp-deployment --to-revision=2

This will immediately revert the Deployment to revision 2.
âœ… Step 3: Verify the Rollback

Check the status of the Deployment:

kubectl rollout status deployment myapp-deployment

Check the Pods to confirm they are running the correct version:

kubectl get pods -l app=myapp

===================================

Configure Environment Variables in Applications =>


ğŸŒ Configuring Environment Variables in Applications in Kubernetes

Kubernetes allows you to pass environment variables to Pods using different methods:

    Using env in the Deployment YAML
    Using ConfigMaps (for non-sensitive data)
    Using Secrets (for sensitive data like passwords)

âœ… 1. Setting Environment Variables Directly in Deployment YAML

You can specify environment variables inside the Deployment YAML using env:

apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp-deployment
spec:
  replicas: 2
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
    spec:
      containers:
      - name: myapp-container
        image: myapp:latest
        env:
        - name: APP_ENV
          value: "production"
        - name: DEBUG_MODE
          value: "false"

ğŸ¯ How It Works

    The app container gets APP_ENV=production and DEBUG_MODE=false.

âœ… 2. Using ConfigMap for Environment Variables

A ConfigMap is used to store non-sensitive data like app configuration.
ğŸ“Œ Step 1: Create a ConfigMap

apiVersion: v1
kind: ConfigMap
metadata:
  name: my-config
data:
  APP_ENV: "production"
  DEBUG_MODE: "false"

ğŸ“Œ Step 2: Reference ConfigMap in Deployment

apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp-deployment
spec:
  replicas: 2
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
    spec:
      containers:
      - name: myapp-container
        image: myapp:latest
        envFrom:
        - configMapRef:
            name: my-config

ğŸ¯ How It Works

    The container gets all key-value pairs from my-config as environment variables.

âœ… 3. Using Secrets for Sensitive Data

A Secret is used for storing sensitive information like passwords or API keys.
ğŸ“Œ Step 1: Create a Secret

apiVersion: v1
kind: Secret
metadata:
  name: my-secret
type: Opaque
data:
  DB_PASSWORD: cGFzc3dvcmQ=  # "password" (Base64 encoded)

    âš  Note: Kubernetes requires values to be Base64-encoded.

ğŸ“Œ Step 2: Reference Secret in Deployment

apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp-deployment
spec:
  replicas: 2
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
    spec:
      containers:
      - name: myapp-container
        image: myapp:latest
        env:
        - name: DB_PASSWORD
          valueFrom:
            secretKeyRef:
              name: my-secret
              key: DB_PASSWORD

ğŸ¯ How It Works

    The DB_PASSWORD is fetched from the Secret and injected into the container.

ğŸ”¥ Quick Commands for Applying Configurations

kubectl apply -f configmap.yaml     # Apply ConfigMap
kubectl apply -f secret.yaml        # Apply Secret
kubectl apply -f deployment.yaml    # Apply Deployment

kubectl get configmap my-config -o yaml  # View ConfigMap
kubectl get secret my-secret -o yaml     # View Secret (Base64 encoded)

======================================

Configuring ConfigMaps in Applications=>

ğŸ“Œ Configuring ConfigMaps in Kubernetes Applications

A ConfigMap in Kubernetes is used to store non-sensitive configuration data as key-value pairs. This data can then be injected into Pods as environment variables, command-line arguments, or mounted files.
ğŸš€ 1ï¸âƒ£ Create a ConfigMap

A ConfigMap can be created in three ways:

    From a YAML file (Recommended)
    From command-line arguments
    From an existing file

ğŸ“Œ 1. Creating a ConfigMap using a YAML File

Create a file called configmap.yaml:

apiVersion: v1
kind: ConfigMap
metadata:
  name: my-config
data:
  APP_ENV: "production"
  LOG_LEVEL: "debug"
  MAX_RETRIES: "5"

ğŸ”¹ Apply the ConfigMap

kubectl apply -f configmap.yaml

Check if itâ€™s created:

kubectl get configmap my-config -o yaml

ğŸ“Œ 2. Creating a ConfigMap from CLI

You can create a ConfigMap directly from the command line:

kubectl create configmap my-config --from-literal=APP_ENV=production --from-literal=LOG_LEVEL=debug

List all ConfigMaps:

kubectl get configmaps

ğŸ“Œ 3. Creating a ConfigMap from a File

If you have a configuration file (e.g., app-config.properties):

kubectl create configmap my-config --from-file=app-config.properties

This creates key-value pairs where the file name is the key and the content is the value.
ğŸš€ 2ï¸âƒ£ Using ConfigMaps in Applications

Once a ConfigMap is created, you can use it in Pods in three ways:

    As environment variables
    As command-line arguments
    As mounted files

ğŸ“Œ 1. Use ConfigMap as Environment Variables

Modify your Deployment YAML:

apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp-deployment
spec:
  replicas: 2
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
    spec:
      containers:
      - name: myapp-container
        image: myapp:latest
        envFrom:
        - configMapRef:
            name: my-config  # Load all key-value pairs as environment variables

ğŸ¯ How It Works

    The container gets all key-value pairs from my-config as environment variables.

To check inside the Pod:

kubectl exec -it <pod-name> -- env | grep APP_ENV

ğŸ“Œ 2. Use ConfigMap as a Single Environment Variable

Instead of loading all keys, you can use a specific key from the ConfigMap:

        env:
        - name: APP_ENV
          valueFrom:
            configMapKeyRef:
              name: my-config
              key: APP_ENV

ğŸ¯ How It Works

    Injects only APP_ENV from my-config.

ğŸ“Œ 3. Use ConfigMap as a Mounted File

You can mount a ConfigMap into a Podâ€™s filesystem.

Modify your Deployment YAML:

apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp-deployment
spec:
  replicas: 2
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
    spec:
      containers:
      - name: myapp-container
        image: myapp:latest
        volumeMounts:
        - name: config-volume
          mountPath: /etc/config   # Mount the ConfigMap here
      volumes:
      - name: config-volume
        configMap:
          name: my-config

ğŸ¯ How It Works

    Mounts the ConfigMap as files inside the container at /etc/config/.
    Each key in the ConfigMap becomes a file with its value as content.

To check inside the Pod:

kubectl exec -it <pod-name> -- cat /etc/config/APP_ENV
================================================

 Configure Secrets in Applications=>

ğŸ” Configuring Secrets in Kubernetes Applications

Kubernetes Secrets store and manage sensitive information like passwords, API keys, and database credentials securely.
ğŸ”¹ 1ï¸âƒ£ Creating a Secret

You can create Secrets in three ways:

    From a YAML file (Recommended)
    From command-line arguments
    From an existing file

ğŸ“Œ 1. Create a Secret using a YAML File

Create a file called secret.yaml:

apiVersion: v1
kind: Secret
metadata:
  name: my-secret
type: Opaque
data:
  DB_USER: dXNlcm5hbWU=    # Base64 encoded "username"
  DB_PASSWORD: cGFzc3dvcmQ=  # Base64 encoded "password"

    âš  Kubernetes requires values to be Base64-encoded.
    You can encode values using:

echo -n "username" | base64

âœ… Apply the Secret

kubectl apply -f secret.yaml

Verify it:

kubectl get secret my-secret -o yaml

    ğŸ›‘ Values are Base64-encoded, not encrypted.

ğŸ“Œ 2. Create a Secret from CLI

kubectl create secret generic my-secret \
  --from-literal=DB_USER=username \
  --from-literal=DB_PASSWORD=password

List all Secrets:
ğŸ” Configuring Secrets in Kubernetes Applications

Kubernetes Secrets store and manage sensitive information like passwords, API keys, and database credentials securely.
ğŸ”¹ 1ï¸âƒ£ Creating a Secret

You can create Secrets in three ways:

    From a YAML file (Recommended)
    From command-line arguments
    From an existing file

ğŸ“Œ 1. Create a Secret using a YAML File

Create a file called secret.yaml:

apiVersion: v1
kind: Secret
metadata:
  name: my-secret
type: Opaque
data:
  DB_USER: dXNlcm5hbWU=    # Base64 encoded "username"
  DB_PASSWORD: cGFzc3dvcmQ=  # Base64 encoded "password"

    âš  Kubernetes requires values to be Base64-encoded.
    You can encode values using:

echo -n "username" | base64

âœ… Apply the Secret

kubectl apply -f secret.yaml

Verify it:

kubectl get secret my-secret -o yaml

    ğŸ›‘ Values are Base64-encoded, not encrypted.

ğŸ“Œ 2. Create a Secret from CLI

kubectl create secret generic my-secret \
  --from-literal=DB_USER=username \
  --from-literal=DB_PASSWORD=password

List all Secrets:

kubectl get secrets

ğŸ“Œ 3. Create a Secret from a File

If you have a file (e.g., db-creds.txt):

kubectl create secret generic my-secret --from-file=db-creds.txt

ğŸš€ 2ï¸âƒ£ Using Secrets in Applications

Secrets can be injected into Pods in three ways:

    As environment variables
    As mounted files
    As command-line arguments

ğŸ“Œ 1. Use Secret as Environment Variables

Modify your Deployment YAML:

apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp-deployment
spec:
  replicas: 2
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
    spec:
      containers:
      - name: myapp-container
        image: myapp:latest
        env:
        - name: DB_USER
          valueFrom:
            secretKeyRef:
              name: my-secret
              key: DB_USER
        - name: DB_PASSWORD
          valueFrom:
            secretKeyRef:
              name: my-secret
              key: DB_PASSWORD

ğŸ¯ How It Works

    Injects DB_USER and DB_PASSWORD from my-secret into the container.

To check inside the Pod:

kubectl exec -it <pod-name> -- env | grep DB_

ğŸ“Œ 2. Use Secret as a Mounted File

Modify your Deployment YAML:

apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp-deployment
spec:
  replicas: 2
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
    spec:
      containers:
      - name: myapp-container
        image: myapp:latest
        volumeMounts:
        - name: secret-volume
          mountPath: "/etc/secrets"
          readOnly: true
      volumes:
      - name: secret-volume
        secret:
          secretName: my-secret

ğŸ¯ How It Works

    Mounts my-secret as files inside the container at /etc/secrets/.
    Each key in the Secret becomes a file, with its value as content.

To check inside the Pod:

kubectl exec -it <pod-name> -- cat /etc/secrets/DB_USER

ğŸ“Œ 3. Use Secret as a Command-Line Argument

Modify your Deployment YAML:

    args: [ "--db-user=$(DB_USER)", "--db-pass=$(DB_PASSWORD)" ]
    env:
    - name: DB_USER
      valueFrom:
        secretKeyRef:
          name: my-secret
          key: DB_USER
    - name: DB_PASSWORD
      valueFrom:
        secretKeyRef:
          name: my-secret
          key: DB_PASSWORD

kubectl get secrets

ğŸ“Œ 3. Create a Secret from a File

If you have a file (e.g., db-creds.txt):

kubectl create secret generic my-secret --from-file=db-creds.txt

ğŸš€ 2ï¸âƒ£ Using Secrets in Applications

Secrets can be injected into Pods in three ways:

    As environment variables
    As mounted files
    As command-line arguments

ğŸ“Œ 1. Use Secret as Environment Variables

Modify your Deployment YAML:

apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp-deployment
spec:
  replicas: 2
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
    spec:
      containers:
      - name: myapp-container
        image: myapp:latest
        env:
        - name: DB_USER
          valueFrom:
            secretKeyRef:
              name: my-secret
              key: DB_USER
        - name: DB_PASSWORD
          valueFrom:
            secretKeyRef:
              name: my-secret
              key: DB_PASSWORD

ğŸ¯ How It Works

    Injects DB_USER and DB_PASSWORD from my-secret into the container.

To check inside the Pod:

kubectl exec -it <pod-name> -- env | grep DB_

ğŸ“Œ 2. Use Secret as a Mounted File

Modify your Deployment YAML:

apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp-deployment
spec:
  replicas: 2
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
    spec:
      containers:
      - name: myapp-container
        image: myapp:latest
        volumeMounts:
        - name: secret-volume
          mountPath: "/etc/secrets"
          readOnly: true
      volumes:
      - name: secret-volume
        secret:
          secretName: my-secret

ğŸ¯ How It Works

    Mounts my-secret as files inside the container at /etc/secrets/.
    Each key in the Secret becomes a file, with its value as content.

To check inside the Pod:

kubectl exec -it <pod-name> -- cat /etc/secrets/DB_USER

ğŸ“Œ 3. Use Secret as a Command-Line Argument

Modify your Deployment YAML:

    args: [ "--db-user=$(DB_USER)", "--db-pass=$(DB_PASSWORD)" ]
    env:
    - name: DB_USER
      valueFrom:
        secretKeyRef:
          name: my-secret
          key: DB_USER
    - name: DB_PASSWORD
      valueFrom:
        secretKeyRef:
          name: my-secret
          key: DB_PASSWORD
=================================================================================================================================================
chapter=6














